{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e75fbc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "use_CPU = False\n",
    "if use_CPU:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import json\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from darknet import Darknet19\n",
    "from loss_function import YOLOv2Loss\n",
    "from image_reader import COCOImageReader, PascalVOCImageReader\n",
    "from data_generator import DataGeneratorFactory\n",
    "from loss_function import YOLOv2Loss\n",
    "\n",
    "import absl.logging\n",
    "absl.logging.set_verbosity(absl.logging.ERROR)\n",
    "\n",
    "np.random.seed(231417)\n",
    "\n",
    "device_names = tf.config.list_physical_devices()\n",
    "\n",
    "print (device_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98189308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of classes = 20\n",
      "number of classes = 20\n",
      "number of training samples = 11987\n",
      "steps per epoch = 1498\n",
      "number of validation samples = 3425\n"
     ]
    }
   ],
   "source": [
    "use_coco = False\n",
    "\n",
    "if use_coco:\n",
    "    train_image_reader = COCOImageReader(data_dir=\"../../../cocodata/\",data_type = \"train2017\",image_size=416,n_tiles=13)\n",
    "    validation_image_reader = COCOImageReader(data_dir=\"../../../cocodata/\",data_type = \"val2017\",image_size=416,n_tiles=13)\n",
    "    anchor_boxes_filename = \"anchor_boxes_coco.json\"\n",
    "else:\n",
    "    train_image_reader = PascalVOCImageReader(data_dir=\"../../../pascalvocdata/VOC2012/\",data_type=\"train\",image_size=416,n_tiles=13)\n",
    "    validation_image_reader = PascalVOCImageReader(data_dir=\"../../../pascalvocdata/VOC2012/\",data_type=\"val\",image_size=416,n_tiles=13)\n",
    "    anchor_boxes_filename = \"anchor_boxes_pascalvoc.json\"\n",
    "\n",
    "# Read anchor boxes from json file\n",
    "with open(anchor_boxes_filename, \"r\", encoding=\"utf8\") as f:\n",
    "            anchor_boxes = json.load(f)\n",
    "\n",
    "\n",
    "train_data_generator = DataGeneratorFactory(anchor_boxes, train_image_reader,random_shuffle=True,max_images=None)\n",
    "validation_data_generator = DataGeneratorFactory(anchor_boxes, validation_image_reader,random_shuffle=True,max_images=None)\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "BBOX_CACHE_SIZE = 4\n",
    "N_EPOCHS = 20\n",
    "N_TRAIN_SAMPLES = train_image_reader.get_n_images()\n",
    "N_VALIDATION_SAMPLES = validation_image_reader.get_n_images()\n",
    "VALIDATION_SUBSPLITS = 1\n",
    "STEPS_PER_EPOCH = N_TRAIN_SAMPLES // BATCH_SIZE\n",
    "VALIDATION_STEPS= N_VALIDATION_SAMPLES // BATCH_SIZE // VALIDATION_SUBSPLITS\n",
    "\n",
    "print (f'number of training samples = {N_TRAIN_SAMPLES:d}')\n",
    "print (f'steps per epoch = {STEPS_PER_EPOCH:d}')\n",
    "print (f'number of validation samples = {N_VALIDATION_SAMPLES:d}')\n",
    "train_batches = train_data_generator.dataset.batch(BATCH_SIZE,drop_remainder=True)\n",
    "validation_batches = validation_data_generator.dataset.batch(BATCH_SIZE,drop_remainder=True)\n",
    "\n",
    "# Checkpoints\n",
    "log_dir = './tb_logs/'\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "\n",
    "checkpoint_dir='./model_checkpoint/'\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_dir,\n",
    "    save_weights_only=False,\n",
    "    save_freq='epoch')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb79efd",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf10166",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "load_model = False\n",
    "save_model = True\n",
    "if load_model:\n",
    "    # Load saved model from disk\n",
    "    model = tf.keras.models.load_model('saved_model',custom_objects={'YOLOv2Loss':YOLOv2Loss})\n",
    "else:\n",
    "    # Start training from scratch\n",
    "    darknet = Darknet19(416, 13, 5, train_image_reader.n_classes)\n",
    "    model = darknet.model\n",
    "    yolov2_loss = YOLOv2Loss(anchor_boxes=anchor_boxes,bbox_cachesize=BBOX_CACHE_SIZE)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.5E-4,beta_1=0.9,beta_2=0.999, epsilon=1.E-8, decay=0.0)\n",
    "    model.compile(loss=yolov2_loss,optimizer=optimizer)\n",
    "\n",
    "model.fit(train_batches,epochs=N_EPOCHS,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          steps_per_epoch=STEPS_PER_EPOCH,\n",
    "          validation_steps=VALIDATION_STEPS,\n",
    "          validation_data=validation_batches,\n",
    "          callbacks=[model_checkpoint_cb,tensorboard_cb])\n",
    "if save_model:\n",
    "    model.save(\"saved_model\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
