{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b3149ec",
   "metadata": {},
   "source": [
    "## YOLOv2 Loss function\n",
    "The loss function is central for a training and it took me a while to understand it properly since it is not given explicitly in the original YOLOv2 paper. The following discussion of the loss function is based on [link to Yumi's blog](https://fairyonice.github.io/Part_4_Object_Detection_with_Yolo_using_VOC_2012_data_loss.html), which is in turn based on the [implementation by experiencor](https://github.com/experiencor/keras-yolo2/blob/master/Yolo%20Step-by-Step.ipynb), fixing some typos along the way.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2334841d",
   "metadata": {},
   "source": [
    "### Total loss function\n",
    "The total loss is given by\n",
    "\n",
    "$$\n",
    "\\text{loss} = \\sum_{i=1}^{S^2}\\sum_{j=1}^B \\left(\\text{loss}_{i,j}^{xywh} + \\text{loss}_{i,j}^p + \\text{loss}_{i,j}^c\\right)\n",
    "$$\n",
    "\n",
    "\n",
    "Here $i=1,\\dots,S^2$ is the index of the gridcell and $j=1,\\dots,B$ is the index of the anchor box slot. Each of the three terms in the loss function will be scaled by a hyperparameter; these hyperparameters are denoted as $\\lambda_{\\text{coord}}$, $\\lambda_{\\text{class}}$ and $\\lambda_{\\text{obj}}$\n",
    "\n",
    "Let $C_{i,j}$ be the ground truth that there is an object associated with anchor box $j$ in grid cell $i$. The the total number of objects in the image is given by\n",
    "\n",
    "$$\n",
    "N_{\\text{obj}} = \\sum_{i=1}^{S^2}\\sum_{j=1}^B C_{i,j}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0811c79",
   "metadata": {},
   "source": [
    "### Loss due to bounding box mismatch (coordinate loss)\n",
    "$$\n",
    "\\text{loss}_{i,j}^{xywh} = \\frac{\\lambda_{\\text{coord}}}{N_{\\text{obj}}} C_{i,j}\\left[\\left(x_{i,j}-\\hat{x}_{i,j}\\right)^2+\\left(y_{i,j}-\\hat{y}_{i,j}\\right)^2+\\left(\\sqrt{w_{i,j}}-\\sqrt{\\hat{w}_{i,j}}\\right)^2+\\left(\\sqrt{h_{i,j}}-\\sqrt{\\hat{h}_{i,j}}\\right)^2\\right]\n",
    "$$\n",
    "\n",
    "Here $x_{i,j}$, $y_{i,j}$, $w_{i,j}$, $h_{i,j}$ are the true coordinates of the centre and width/height of the bounding box. The corresponding predicted values $\\hat{x}_{i,j}$, $\\hat{y}_{i,j}$, $\\hat{w}_{i,j}$, $\\hat{h}_{i,j}$ are indicated with a hat. Since each term is multiplied by $C_{i,j}\\in\\{0,1\\}$, the coordinate loss only contributes for those $i,j$ which correspond to a true bounding box."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2e9a8a",
   "metadata": {},
   "source": [
    "### Classification loss\n",
    "\n",
    "Let $p_{i,j}^{c}\\in\\{0,1\\}$ be the ground truth probability that the object associated with $i,j$ is of class $c\\in\\text{classes}$. The corresponding predicted probabilities $\\hat{p}_{i,j}^c$ are denoted with a hat. Then the classification loss in $i,j$ is given by the cross-entropy\n",
    "\n",
    "$$\n",
    "\\text{loss}_{i,j}^{c} = -\\frac{\\lambda_{\\text{class}}}{N_{\\text{obj}}} C_{i,j} \\sum_{c\\in\\text{classes}} p_{i,j}^c \\log\\left(\\hat{p}_{i,j}^c\\right).\n",
    "$$\n",
    "\n",
    "Again, since we multiply each term by $C_{i,j}\\in\\{0,1\\}$, only those $i,j$ which are associated with a real object contribute."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30702d3f",
   "metadata": {},
   "source": [
    "### Confidence loss\n",
    "\n",
    "Define\n",
    "\n",
    "$$\n",
    "C_{i,j}^{\\text{noobj}} = \\begin{cases}\n",
    "1 & \\text{if $\\max_{i',j'}\\left\\{\\text{IoU}\\left(\\mathcal{B}(x_{i',j'},y_{i',j'},w_{i',j'},h_{i',j'}),\\mathcal{B}(\\hat{x}_{i,j},\\hat{y}_{i,j},\\hat{w}_{i,j},\\hat{h}_{i,j})\\right)\\right\\} < 0.6$ and $C_{i,j}=0$}\\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases}.\n",
    "$$\n",
    "\n",
    "Here $\\mathcal{B}(x,y,w,h)$ denotes the bounding box with centre coordinate $x,y$ and width/height $w,h$. $\\text{IoU}\\left(\\mathcal{B}_a,\\mathcal{B}_b\\right)$ is the *''intersection over union''* of two bounding boxes $\\mathcal{B}_a$ and $\\mathcal{B}_b$.\n",
    "\n",
    "Further, let\n",
    "\n",
    "$$\n",
    "N^{\\text{conf}} = \\sum_{i=1}^{S^2}\\sum_{j=1}^B\\left(C_{i,j}+C_{i,j}^{\\text{noobj}}\\right).\n",
    "$$\n",
    "\n",
    "Then the confidence loss is\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{loss}_{i,j}^{c} &= \\frac{\\lambda_{\\text{obj}}}{N^{\\text{conf}}} C_{i,j}\\left(\\text{IoU}\\left(\\mathcal{B}(x_{i,j},y_{i,j},w_{i,j},h_{i,j}),\\mathcal{B}(\\hat{x}_{i,j},\\hat{y}_{i,j},\\hat{w}_{i,j},\\hat{h}_{i,j})\\right)-\\hat{C}_{i,j}\\right)^2\\\\\n",
    "&\\quad+\\;\\; \\frac{\\lambda_{\\text{noobj}}}{N^{\\text{conf}}} C_{i,j}\\left(0-\\hat{C}_{i,j}\\right)^2\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where $\\hat{C}_{i,j}$ is the predicted confidence of finding an object in $i,j$. Note that I think that in [Yumi's blog](https://fairyonice.github.io/Part_4_Object_Detection_with_Yolo_using_VOC_2012_data_loss.html) a square is missing in the second line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e809219",
   "metadata": {},
   "source": [
    "\n",
    "### Final comments\n",
    "I believe that there is a bug in Yumi's `get_conf_mask()` function: the penultimate line should read \n",
    "```Python\n",
    "conf_mask = conf_mask + true_box_conf * LAMBDA_OBJECT\n",
    "```\n",
    "(i.e. `true_box_conf_IOU` needs to be replaced by `true_box_conf`) to be consistent with the experiencor's implementation and the discussion in the blog.\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
